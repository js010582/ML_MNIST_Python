{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST & sklearn: Jasper Sandhu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the required libraries for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "# from mnist import MNIST\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# use LaTeX fonts in the plot\n",
    "# plt.rc('text', usetex=True)\n",
    "# plt.rc('font', family='serif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MNIST dataset from mnist library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file:\n",
      "Total training images 60000\n",
      "Total training labels 60000\n",
      "Total test images 10000\n",
      "Total test labels 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset from file:\")\n",
    "\n",
    "mndata = MNIST('dataset/extract')\n",
    "\n",
    "#Loading images and labels into 2 sets of data arrays.\n",
    "trainimages, trainlabels = mndata.load_training()\n",
    "testimages, testlabels = mndata.load_testing()\n",
    "\n",
    "print(\"Total training images\",len(trainimages))\n",
    "print(\"Total training labels\",len(trainlabels))\n",
    "print(\"Total test images\",len(testimages))\n",
    "print(\"Total test labels\",len(testlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The size of the array match the information from \"http://yann.lecun.com/exdb/mnist/\". Performing additional inspection on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images dimension:  (60000, 784)\n",
      "Training labels dimension:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "#print(trainimages.shape)\n",
    "print(\"Training images dimension: \", np.shape(trainimages))\n",
    "print(\"Training labels dimension: \", np.shape(trainlabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The training images are in a [784 x 1] array while the training labels are in a [1 x 1] (instead of one hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decided to create a function to perform a sanity check on the labels of the 60,000 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Array to Check\n",
    "def datacheck(dataset):\n",
    "    totalcount = 0\n",
    "    for x in range(0,10):\n",
    "        count = 0\n",
    "        for y in range(len(dataset)):\n",
    "            if dataset[y] == x:\n",
    "                count+=1\n",
    "        totalcount+=count\n",
    "        print(\"Data with labels:\", x, \"\\tWith counts:\", count, \"\\nTotal:\", totalcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with labels: 0 \tWith counts: 5923 \n",
      "Total: 5923\n",
      "Data with labels: 1 \tWith counts: 6742 \n",
      "Total: 12665\n",
      "Data with labels: 2 \tWith counts: 5958 \n",
      "Total: 18623\n",
      "Data with labels: 3 \tWith counts: 6131 \n",
      "Total: 24754\n",
      "Data with labels: 4 \tWith counts: 5842 \n",
      "Total: 30596\n",
      "Data with labels: 5 \tWith counts: 5421 \n",
      "Total: 36017\n",
      "Data with labels: 6 \tWith counts: 5918 \n",
      "Total: 41935\n",
      "Data with labels: 7 \tWith counts: 6265 \n",
      "Total: 48200\n",
      "Data with labels: 8 \tWith counts: 5851 \n",
      "Total: 54051\n",
      "Data with labels: 9 \tWith counts: 5949 \n",
      "Total: 60000\n"
     ]
    }
   ],
   "source": [
    "#Performing a sanity check on the data\n",
    "datacheck(trainlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Was experimenting with reshape to convert the flattened image back into a 28x28 for pyplot output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleimagecheck(data_images = trainimages, count = 0):\n",
    "        #access first image\n",
    "        first_image = data_images[count]\n",
    "        print (trainlabels[count])\n",
    "    \n",
    "        first_image = np.array(first_image, dtype='uint8')\n",
    "        pixels = first_image.reshape((28, 28))\n",
    "        plt.imshow(pixels, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagecheck(data_images = trainimages, rows = 1, columns = 1, count = 0):\n",
    "    selection = rows * columns\n",
    "    j = 1 #for plot index\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "    for x in range(selection):\n",
    "        disp_image = data_images[x]\n",
    "        disp_image = np.array(disp_image, dtype='uint8')\n",
    "        plt.subplot(rows, columns, j)\n",
    "        disp_pixels = disp_image.reshape((28,28)) #converting the flat array back into a 28x28\n",
    "        plt.imshow(disp_pixels, cmap='gray') #displays the image\n",
    "        #plt.text(0, 0, \"\\#:{}\".format(x))\n",
    "        j+=1 #increment plot index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagecheck(trainimages, 5, 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After gaining familiarity with the data it's time to resume with the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all the 9s!\n",
    "\n",
    "#### \"In this secion you should build up a classifier that can distinguish number 9 from every other numbers. (reusing code and libraries are okay as long as you explain what is going on). For each section below you need to measure your performance. So, make sure to run the performance check at every part.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Find the 9s using K-Nearest neighbors for Minkowski metric of order (1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Array Size trimmed:\n",
      "Total training images: 4335\n",
      "Total training labels 4335\n",
      "Total training images 765\n",
      "Total training labels 765\n",
      "Total test images 900\n",
      "Total test labels 900\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Reducing the dataset into a smaller sample size (10% of Population). Going with 70% Training, 15% Validation, 15% Test of 6000 total size \n",
    "print(\"\\nNew Array Size trimmed:\")\n",
    "\n",
    "#Splitting Splitting into 85/15 Training/Test\n",
    "(tr_images, te_images, tr_labels, te_labels) = train_test_split(trainimages[:6000], trainlabels[:6000], test_size =0.15)\n",
    "\n",
    "#Splitting 85/15 Training/Validation (Training is now 70%)\n",
    "(tr_images, val_images, tr_labels, val_labels) = train_test_split(tr_images, tr_labels, test_size=0.15, random_state = 20)\n",
    "\n",
    "\n",
    "print(\"Total training images: {}\".format(len(tr_images)))\n",
    "print(\"Total training labels\",len(tr_labels))\n",
    "print(\"Total training images\",len(val_images))\n",
    "print(\"Total training labels\",len(val_labels))\n",
    "print(\"Total test images\",len(te_images))\n",
    "print(\"Total test labels\",len(te_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Neighbors = 1, Score of: 94.12%\n",
      "K Neighbors = 2, Score of: 92.81%\n",
      "K Neighbors = 3, Score of: 94.64%\n",
      "K Neighbors = 4, Score of: 93.59%\n",
      "K Neighbors = 5, Score of: 93.20%\n",
      "K Neighbors = 6, Score of: 92.94%\n",
      "K Neighbors = 7, Score of: 92.55%\n",
      "K Neighbors = 8, Score of: 92.68%\n",
      "K Neighbors = 9, Score of: 92.94%\n",
      "K Neighbors = 10, Score of: 92.81%\n",
      "K Neighbors = 11, Score of: 92.68%\n",
      "K Neighbors = 12, Score of: 92.29%\n",
      "K Neighbors = 13, Score of: 91.50%\n",
      "K Neighbors = 14, Score of: 91.37%\n",
      "K Neighbors = 15, Score of: 90.98%\n"
     ]
    }
   ],
   "source": [
    "#knn(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None, **kwargs) From website for reference.\n",
    "\n",
    "kval = range(1,16) #1 to 15 range of k neighbors to use\n",
    "#kval = [1,5,10,15,20,25,30,35,40,50,55] #experimented with higher range to see where it dropped off\n",
    "\n",
    "total_scores = []\n",
    "\n",
    "for x in kval:\n",
    "    knnclass = KNeighborsClassifier(n_neighbors=x) #Creating an object from a KNeighborsClassifer\n",
    "          \n",
    "    knnclass.fit(tr_images, tr_labels) #Training the model with our training data\n",
    "    \n",
    "    temp_scores = knnclass.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "    print(\"K Neighbors = {0}, Score of: {1:2.2f}%\".format(x,(temp_scores*100)))\n",
    "          \n",
    "    total_scores.append(temp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest accuracy was using a K value of: 3, giving an accuracy of 94.64%\n"
     ]
    }
   ],
   "source": [
    "highest_score = np.argmax(total_scores)\n",
    "print(\"The highest accuracy was using a K value of: {0}, giving an accuracy of {1:2.2f}%\".format(highest_score+1, total_scores[highest_score]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying different different orders of Minkowski Metric (1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minkowski Metric of : 1, Score of: 93.46%\n",
      "Minkowski Metric of : 2, Score of: 94.12%\n",
      "Minkowski Metric of : 3, Score of: 93.99%\n"
     ]
    }
   ],
   "source": [
    "#knn(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None, **kwargs) From website for reference.\n",
    "\n",
    "kval = 1 #Using K = 1 that we found earlier.\n",
    "mink_metric = range (1,4) #Used to check for different minkowski metric from 1 - 3\n",
    "total_scores = []\n",
    "\n",
    "for x in mink_metric:\n",
    "    knnclass = KNeighborsClassifier(n_neighbors=kval, p=x) #Creating an object from a KNeighborsClassifer\n",
    "          \n",
    "    knnclass.fit(tr_images, tr_labels) #Training the model with our training data\n",
    "    \n",
    "    temp_scores = knnclass.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "    print(\"Minkowski Metric of : {0}, Score of: {1:2.2f}%\".format(x,(temp_scores*100)))\n",
    "          \n",
    "    total_scores.append(temp_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a K value of 3, and a Minkowski Metric of 3, we can find the total amount of 9's in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest of : 3, Minkowski Metric of : 3, Score of: 95.16%\n"
     ]
    }
   ],
   "source": [
    "kval = 3 #K-Nearest Neighbor\n",
    "pval = 3 #Minkowski Metric\n",
    "knnclass = KNeighborsClassifier(n_neighbors=kval, p=pval)\n",
    "knnclass.fit(tr_images, tr_labels) #Training the model with our training data\n",
    "temp_scores = knnclass.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "print(\"K-Nearest of : {0}, Minkowski Metric of : {1}, Score of: {2:2.2f}%\".format(kval,pval,(temp_scores*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = knnclass.predict(te_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Created \"findresults\" to filter the results from running the prediction on the test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findresults(predicted_values = predicted_values ,value = 0):\n",
    "    pred_count = 0\n",
    "    actu_count = 0\n",
    "    incorrect_count = 0\n",
    "    faulty_images = []\n",
    "\n",
    "    for x in np.arange(len(predicted_values)):\n",
    "        if predicted_values[x] == value:\n",
    "            pred_count+=1\n",
    "\n",
    "    for y in np.arange(len(te_labels)): \n",
    "        if te_labels[y] == value:\n",
    "            actu_count+=1\n",
    "\n",
    "    for z in np.arange(len(predicted_values)):\n",
    "        if predicted_values[z] == value and te_labels[z] != value:\n",
    "            print(\"Incorrect match of {0} : {1} and {2}\".format(value,predicted_values[z],te_labels[z]))\n",
    "            faulty_images.append(te_images[z])\n",
    "            incorrect_count+=1\n",
    "\n",
    "    real_count = pred_count - incorrect_count\n",
    "    print(\"Incorectly classified: {}\".format(incorrect_count))\n",
    "    print(\"Predicted Count: {} from the Actual Count in the test set: {}\".format(pred_count, actu_count))\n",
    "    print(\"Actually found: {0} giving a accuracy of {1:2.2f}%\".format(real_count,(real_count/actu_count)*100))\n",
    "    return faulty_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 1\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorectly classified: 8\n",
      "Predicted Count: 95 from the Actual Count in the test set: 93\n",
      "Actually found: 87 giving a accuracy of 93.55%\n"
     ]
    }
   ],
   "source": [
    "faults = findresults(predicted_values, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the function written earlier to display the falsely classified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagecheck(faults,len(faults))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like the model struggled with partially written 4's and other handwritten text that aren't too far from looking like 9's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Find the 9s using Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of: 78.56%\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(criterion=\"gini\", max_depth = 100)\n",
    "dt_classifier.fit(tr_images, tr_labels)\n",
    "temp_scores = dt_classifier.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "print(\"Score of: {0:2.2f}%\".format(temp_scores*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It's likely our accuracy would increase if we increased our Train/Validation/Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 6\n",
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 6\n",
      "Incorrect match of 9 : 9 and 0\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 2\n",
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 2\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 2\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 3\n",
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 3\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 0\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorectly classified: 24\n",
      "Predicted Count: 83 from the Actual Count in the test set: 93\n",
      "Actually found: 59 giving a accuracy of 63.44%\n"
     ]
    }
   ],
   "source": [
    "predicted_values = dt_classifier.predict(te_images)\n",
    "faults = findresults(predicted_values, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Judging by our results it seems we've dramatically reduced our accuracy from KNN. Some improvement could be seen by spending time running through different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Find the 9s using Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of: 78.56%\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 100, max_depth = 3)\n",
    "rf_classifier.fit(tr_images, tr_labels)\n",
    "temp_scores = dt_classifier.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "print(\"Score of: {0:2.2f}%\".format(temp_scores*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect match of 9 : 9 and 3\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 7\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 3\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 1\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 4\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 3\n",
      "Incorrect match of 9 : 9 and 5\n",
      "Incorrect match of 9 : 9 and 8\n",
      "Incorrect match of 9 : 9 and 3\n",
      "Incorectly classified: 28\n",
      "Predicted Count: 75 from the Actual Count in the test set: 93\n",
      "Actually found: 47 giving a accuracy of 50.54%\n"
     ]
    }
   ],
   "source": [
    "predicted_values = rf_classifier.predict(te_images)\n",
    "faults = findresults(predicted_values, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seems like our accuracy is much worst than using KNN and Decision Tree. Again more time could be spent optimizing the parameters to help improve the accuracy using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secion 2: Classify the Handwritten digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. \"First forget about the labels and run the k-means algorithm to find whether there is an underlying patterns. So, first find the k clusters (here is obviously 10 clusters). Then look at their labels and find the accuracy. By doing this you are turning a supervised learning into an unsupervised learning!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the function earlier and modifying it to show all the found numbers after running model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allresults(predicted_values = predicted_values, value = 0):\n",
    "    pred_count = 0\n",
    "    actu_count = 0\n",
    "    incorrect_count = 0\n",
    "    faulty_images = []\n",
    "\n",
    "    for x in np.arange(len(predicted_values)):\n",
    "        if predicted_values[x] == value:\n",
    "            pred_count+=1\n",
    "\n",
    "    for y in np.arange(len(te_labels)): \n",
    "        if te_labels[y] == value:\n",
    "            actu_count+=1\n",
    "\n",
    "    for z in np.arange(len(predicted_values)):\n",
    "        if predicted_values[z] == value and te_labels[z] != value:\n",
    "            #print(\"Incorrect match of {0} : {1} and {2}\".format(value,predicted_values[z],te_labels[z]))\n",
    "            faulty_images.append(te_images[z])\n",
    "            incorrect_count+=1\n",
    "\n",
    "    real_count = pred_count - incorrect_count\n",
    "    #print(\"Incorectly classified: {}\".format(incorrect_count))\n",
    "    #print(\"Predicted Count: {} from the Actual Count in the test set: {}\".format(pred_count, actu_count))\n",
    "    print(\"Actual found {0}: {1} giving a accuracy of {2:2.2f}%\".format(value, real_count,(real_count/actu_count)*100))\n",
    "#   return faulty_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "                  \n",
    "km_clusters = KMeans(n_clusters=10).fit(tr_images)\n",
    "tr_images_trained = km_clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_clusters.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm at a loss at how to accurately re-label the clusters to represent what they should be when accuracy is relatively poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Find the digits using K-Nearest neighbours for Minkowski metric of order (1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minkowski Metric of : 1, Score of: 93.46%\n",
      "Minkowski Metric of : 2, Score of: 94.12%\n",
      "Minkowski Metric of : 3, Score of: 93.99%\n"
     ]
    }
   ],
   "source": [
    "#knn(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None, **kwargs) From website for reference.\n",
    "\n",
    "kval = 1 #Using K = 1 that we found earlier.\n",
    "mink_metric = range (1,4) #Used to check for different minkowski metric from 1 - 3\n",
    "total_scores = []\n",
    "\n",
    "for x in mink_metric:\n",
    "    knnclass = KNeighborsClassifier(n_neighbors=kval, p=x) #Creating an object from a KNeighborsClassifer\n",
    "          \n",
    "    knnclass.fit(tr_images, tr_labels) #Training the model with our training data\n",
    "    \n",
    "    temp_scores = knnclass.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "    print(\"Minkowski Metric of : {0}, Score of: {1:2.2f}%\".format(x,(temp_scores*100)))\n",
    "          \n",
    "    total_scores.append(temp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest of : 3, Minkowski Metric of : 3, Score of: 95.16%\n"
     ]
    }
   ],
   "source": [
    "kval = 3 #K-Nearest Neighbor\n",
    "pval = 3 #Minkowski Metric\n",
    "knnclass = KNeighborsClassifier(n_neighbors=kval, p=pval)\n",
    "knnclass.fit(tr_images, tr_labels) #Training the model with our training data\n",
    "temp_scores = knnclass.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "print(\"K-Nearest of : {0}, Minkowski Metric of : {1}, Score of: {2:2.2f}%\".format(kval,pval,(temp_scores*100)))\n",
    "predicted_values = knnclass.predict(te_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Find the digits using Decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of: 77.52%\n"
     ]
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(criterion=\"gini\", max_depth = 100)\n",
    "dt_classifier.fit(tr_images, tr_labels)\n",
    "temp_scores = dt_classifier.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "print(\"Score of: {0:2.2f}%\".format(temp_scores*100))\n",
    "predicted_values = dt_classifier.predict(te_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual found 0: 83 giving a accuracy of 85.57%\n",
      "Actual found 1: 88 giving a accuracy of 86.27%\n",
      "Actual found 2: 60 giving a accuracy of 64.52%\n",
      "Actual found 3: 62 giving a accuracy of 63.92%\n",
      "Actual found 4: 74 giving a accuracy of 83.15%\n",
      "Actual found 5: 60 giving a accuracy of 77.92%\n",
      "Actual found 6: 62 giving a accuracy of 83.78%\n",
      "Actual found 7: 72 giving a accuracy of 80.00%\n",
      "Actual found 8: 63 giving a accuracy of 71.59%\n",
      "Actual found 9: 56 giving a accuracy of 60.22%\n"
     ]
    }
   ],
   "source": [
    "predicted_values = dt_classifier.predict(te_images)\n",
    "for x in range(10):\n",
    "    allresults(predicted_values, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Find the digits using Random Forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of: 77.52%\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators = 100, max_depth = 3)\n",
    "rf_classifier.fit(tr_images, tr_labels)\n",
    "temp_scores = dt_classifier.score(val_images, val_labels) #Using our validation set to check for accuracies\n",
    "print(\"Score of: {0:2.2f}%\".format(temp_scores*100))\n",
    "predicted_values = rf_classifier.predict(te_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual found 0: 96 giving a accuracy of 98.97%\n",
      "Actual found 1: 98 giving a accuracy of 96.08%\n",
      "Actual found 2: 49 giving a accuracy of 52.69%\n",
      "Actual found 3: 72 giving a accuracy of 74.23%\n",
      "Actual found 4: 78 giving a accuracy of 87.64%\n",
      "Actual found 5: 13 giving a accuracy of 16.88%\n",
      "Actual found 6: 66 giving a accuracy of 89.19%\n",
      "Actual found 7: 77 giving a accuracy of 85.56%\n",
      "Actual found 8: 55 giving a accuracy of 62.50%\n",
      "Actual found 9: 33 giving a accuracy of 35.48%\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    allresults(predicted_values, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Comment on any significant difference between your results for the binary classifier vs multi-class classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After going through all this and answering this question, I can see the first part was to be a binary classifier but I ended up using a multi-class classifier to find individual digits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
